# Setup config
# ------------
project_name: CompositeTasking
which_system: composite_tasking
which_cluster: eth

# Data set & task palette config
# ------------------------------
img_size:
  - 32
  - 32
task_code_len: 20
palette_mode: semantic_rule_R2
task_list:
  - parts
  - seg
  - normals
  - saliency 
  - edges 
  
# Model config    
# ------------
which_model: composite_tasking_net_v0

encoder_arch: resnet18
encoder_pre_trained: true
decoder_arch: None

n_fc_z_map: 6
latent_w_dim: 128

#which_cond: task_composition_v1
which_cond: task_composition_v1
cond_cfg_txt: cond_batch1x1

skip_conv_ks: 1
dec_conv_ks: 3
net_output_ch: 3

# Training config    
# ---------------
optimizer: adam
lr: 0.00001
lr_div_encoder: 100.0
lr_scheduler: reduce_on_plateau
lr_scheduler_step: 30
lr_scheduler_factor: 0.3
lr_scheduler_patience: 12
pl_grad_clip_val: 0.0
wd: 0.00001
sgd_momentum: 0.9
sgd_nesterov_momentum: true

pl_max_epochs: 100
pl_min_epochs: 100
pl_early_stop_patience: -1
b_size: 2
n_workers: 0

seg_l_focal_gamma: 2.0

pl_benchmark: true
pl_precision: 32
pl_sync_batchnorm: true
pl_which_profiler: simple

pl_progress_bar_refresh_rate: 100
pl_log_every_n_steps: 100
pl_flush_logs_every_n_steps: 100
pl_check_val_every_n_epoch: 1
pl_limit_train_batches: 1.0
pl_limit_val_batches: 1.0

debug: true
message: ...This is a debugging configuration & experiment...